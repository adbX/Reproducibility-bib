@inproceedings{repro-fast-sum,
	crossref={6545904}
}
ARITH21_Fast_Sum.pdf

@INPROCEEDINGS{6545904, 
	author={J. Demmel and H. D. Nguyen}, 
	booktitle={Computer Arithmetic (ARITH), 2013 21st IEEE Symposium on}, 
	title={Fast Reproducible Floating-Point Summation}, 
	year={2013}, 
	pages={163-172}, 
	keywords={floating point arithmetic;parallel processing;scheduling;Rump algorithm;correctness check;debugging;dynamic scheduling;error-free vector transformation;floating point nonassociativity;floating-point operation;floating-point summation;parallel computing resource;reduction operation;reproducibility property;rounding mode;summation order;Accuracy;Algorithm design and analysis;Educational institutions;Numerical analysis;Parallel processing;Program processors;Vectors;floating-point;parallelism;reproducibility;rounding error;summation}, 
	doi={10.1109/ARITH.2013.9}, 
	ISSN={1063-6889}, 
	month={April},}

@article{collberg2014measuring,
	title={Measuring reproducibility in computer systems research},
	author={Collberg, Christian and Proebsting, Todd and Moraila, Gina and Shankaran, Akash and Shi, Zuoming and Warren, Alex M},
	journal={Unpublished report},
	url={https://reproducibility.cs.arizona.edu},
	year={2014},
	month={October},
	day={10}
}
tr.pdf

@article{stodden-reproducibility-crisis,
	crossref={doi:10.1109/MCSE.2009.15}
}
Stodden_Reproducibility_Crisis.pdf

@article{doi:10.1109/MCSE.2009.15,
  author = {David L. Donoho and Arian Maleki and Inam Ur Rahman and Morteza Shahram and Victoria Stodden},
  title = {Reproducible Research in Computational Harmonic Analysis},
  journal = {Computing in Science \& Engineering},
  volume = {11},
  number = {1},
  pages = {8-18},
  year = {2009},
  doi = {10.1109/MCSE.2009.15},

  URL = { http://aip.scitation.org/doi/abs/10.1109/MCSE.2009.15 },
  eprint = { http://aip.scitation.org/doi/pdf/10.1109/MCSE.2009.15 },
  abstract = { Scientific computation is emerging as absolutely central to the scientific method. Unfortunately, it’s error-prone and currently immature—traditional scientific publication is incapable of finding and rooting out errors in scientific computation—which must be recognized as a crisis. An important recent development and a necessary response to the crisis is reproducible computational research in which researchers publish the article along with the full computational environment that produces the results. The authors have practiced reproducible computational research for 15 years and have integrated it with their scientific research and with doctoral and postdoctoral education. In this article, they review their approach and how it has evolved over time, discussing the arguments for and against working reproducibly. }
}

@article{problem-of-reproducibility,
	crossref={doi:10.1080/09332480.2012.726554}
}
The_Problem_of_Reproducibility.pdf

@article{doi:10.1080/09332480.2012.726554,
	author = { Darrel   Ince },
	title = {The Problem of Reproducibility},
	journal = {CHANCE},
	volume = {25},
	number = {3},
	pages = {4-7},
	year = {2012},
	doi = {10.1080/09332480.2012.726554},
	URL = { 
		http://dx.doi.org/10.1080/09332480.2012.726554
	},
	eprint = { 
	http://dx.doi.org/10.1080/09332480.2012.726554
	}
}

@article{classification-of-methodologies-large-scale,
	crossref={gustedt:inria-00364180}
}
RR-6859.pdf

@article{gustedt:inria-00364180,
	TITLE = {{Experimental Methodologies for Large-Scale Systems: a Survey}},
	AUTHOR = {Gustedt, Jens and Jeannot, Emmanuel and Quinson, Martin},
	URL = {https://hal.inria.fr/inria-00364180},
	JOURNAL = {{Parallel Processing Letters}},
	HAL_LOCAL_REFERENCE = {RR-6859},
	PUBLISHER = {{World Scientific Publishing}},
	VOLUME = {19},
	NUMBER = {3},
	PAGES = {399-418},
	YEAR = {2009},
	DOI = {10.1142/S0129626409000304},
	KEYWORDS = {Experimental computer science ; experimental methodologies ; in-situ ; emulation ; benchmarking ; simulation},
	PDF = {https://hal.inria.fr/inria-00364180/file/RR-6859.pdf},
	HAL_ID = {inria-00364180},
	HAL_VERSION = {v2},
}

@article{quantifying-reproducibility-computational-biology,
	crossref={10.1371/journal.pone.0080278}
}

@article{10.1371/journal.pone.0080278,
	author = {Garijo, Daniel AND Kinnings, Sarah AND Xie, Li AND Xie, Lei AND Zhang, Yinliang AND Bourne, Philip E. AND Gil, Yolanda},
	journal = {PLoS ONE},
	publisher = {Public Library of Science},
	title = {Quantifying Reproducibility in Computational Biology: The Case of the Tuberculosis Drugome},
	year = {2013},
	month = {11},
	volume = {8},
	url = {"http://dx.doi.org/10.1371\%2Fjournal.pone.0080278"},
	pages = {1-11},
	abstract = {<p>How easy is it to reproduce the results found in a typical computational biology paper? Either through experience or intuition the reader will already know that the answer is with difficulty or not at all. In this paper we attempt to quantify this difficulty by reproducing a previously published paper for different classes of users (ranging from users with little expertise to domain experts) and suggest ways in which the situation might be improved. Quantification is achieved by estimating the time required to reproduce each of the steps in the method described in the original paper and make them part of an explicit workflow that reproduces the original results. Reproducing the method took several months of effort, and required using new versions and new software that posed challenges to reconstructing and validating the results. The quantification leads to “reproducibility maps” that reveal that novice researchers would only be able to reproduce a few of the steps in the method, and that only expert researchers with advance knowledge of the domain would be able to reproduce the method in its entirety. The workflow itself is published as an online resource together with supporting software and data. The paper concludes with a brief discussion of the complexities of requiring reproducibility in terms of cost versus benefit, and a desiderata with our observations and guidelines for improving reproducibility. This has implications not only in reproducing the work of others from published papers, but reproducing work from one’s own laboratory.</p>},
	number = {11},
	doi = {10.1371/journal.pone.0080278}
}

@article{collaborative-reproducibility,
	crossref={Chirigati201695}
}
1-s2.0-S0306437916300813-main.pdf

@article{Chirigati201695,
title = "A collaborative approach to computational reproducibility",
journal = "Information Systems",
volume = "59",
number = "",
pages = "95 - 97",
year = "2016",
note = "",
issn = "0306-4379",
doi = "http://dx.doi.org/10.1016/j.is.2016.03.002",
url = "http://www.sciencedirect.com/science/article/pii/S0306437916300813",
author = "Fernando Chirigati and Rebecca Capone and Rémi Rampin and Juliana Freire and Dennis Shasha"
}

@article{tools-and-techniques-computational-reproducibility,
	crossref={Piccolo2016}
}
ToolsAndTechniquesComputationalReproducibilityPicollo2016.pdf

@Article{Piccolo2016,
author="Piccolo, Stephen R.
and Frampton, Michael B.",
title="Tools and techniques for computational reproducibility",
journal="GigaScience",
year="2016",
volume="5",
number="1",
pages="1--13",
abstract="When reporting research findings, scientists document the steps they followed so that others can verify and build upon the research. When those steps have been described in sufficient detail that others can retrace the steps and obtain similar results, the research is said to be reproducible. Computers play a vital role in many research disciplines and present both opportunities and challenges for reproducibility. Computers can be programmed to execute analysis tasks, and those programs can be repeated and shared with others. The deterministic nature of most computer programs means that the same analysis tasks, applied to the same data, will often produce the same outputs. However, in practice, computational findings often cannot be reproduced because of complexities in how software is packaged, installed, and executed---and because of limitations associated with how scientists document analysis steps. Many tools and techniques are available to help overcome these challenges; here we describe seven such strategies. With a broad scientific audience in mind, we describe the strengths and limitations of each approach, as well as the circumstances under which each might be applied. No single strategy is sufficient for every scenario; thus we emphasize that it is often useful to combine approaches.",
issn="2047-217X",
doi="10.1186/s13742-016-0135-4",
url="http://dx.doi.org/10.1186/s13742-016-0135-4"
}

@article{repeatability-microarray-gene-expression,
	crossref={Ioannidis2009}
}
ng.295.pdf

@Article{Ioannidis2009,
	author={Ioannidis, John P. A. and Allison, David B. and Ball, Catherine A. and Coulibaly, Issa and Cui, Xiangqin and Culhane, Aedin C. and Falchi, Mario and Furlanello, Cesare and Game, Laurence and Jurman, Giuseppe and Mangion, Jon and Mehta, Tapan and Nitzberg, Michael and Page, Grier P. and Petretto, Enrico and van Noort, Vera},
	title={Repeatability of published microarray gene expression analyses},
	journal={Nat Genet},
	year={2009},
	month={Feb},
	publisher={Nature Publishing Group},
	volume={41},
	number={2},
	pages={149-155},
	issn={1061-4036},
	doi={10.1038/ng.295},
	url={http://dx.doi.org/10.1038/ng.295}
}

@article{fmri-false-positives,
	crossref={Eklund12072016}
}
PNAS-2016-Eklund-7900-5.pdf

@article{Eklund12072016,
	author = {Eklund, Anders and Nichols, Thomas E. and Knutsson, Hans}, 
	title = {Cluster failure: Why fMRI inferences for spatial extent have inflated false-positive rates},
	volume = {113}, 
	number = {28}, 
	pages = {7900-7905}, 
	year = {2016}, 
	doi = {10.1073/pnas.1602413113}, 
	abstract ={The most widely used task functional magnetic resonance imaging (fMRI) analyses use parametric statistical methods that depend on a variety of assumptions. In this work, we use real resting-state data and a total of 3 million random task group analyses to compute empirical familywise error rates for the fMRI software packages SPM, FSL, and AFNI, as well as a nonparametric permutation method. For a nominal familywise error rate of 5\%, the parametric statistical methods are shown to be conservative for voxelwise inference and invalid for clusterwise inference. Our results suggest that the principal cause of the invalid cluster inferences is spatial autocorrelation functions that do not follow the assumed Gaussian shape. By comparison, the nonparametric permutation test is found to produce nominal results for voxelwise as well as clusterwise inference. These findings speak to the need of validating the statistical methods being used in the field of neuroimaging.}, 
	URL = {http://www.pnas.org/content/113/28/7900.abstract}, 
	eprint = {http://www.pnas.org/content/113/28/7900.full.pdf}, 
	journal = {Proceedings of the National Academy of Sciences} 
}

@article{reproducibility-computational-biology,
	crossref={Lewis2016}
}
WhereNextForComputationalBiology.pdf

@Article{Lewis2016,
	author="Lewis, Joanna and Breeze, Charles E. and Charlesworth, Jane and Maclaren, Oliver J. and Cooper, Jonathan",
	title="Where next for the reproducibility agenda in computational biology?",
	journal="BMC Systems Biology",
	year="2016",
	volume="10",
	number="1",
	pages="1--10",
	abstract="The concept of reproducibility is a foundation of the scientific method. With the arrival of fast and powerful computers over the last few decades, there has been an explosion of results based on complex computational analyses and simulations. The reproducibility of these results has been addressed mainly in terms of exact replicability or numerical equivalence, ignoring the wider issue of the reproducibility of conclusions through equivalent, extended or alternative methods.",
	issn="1752-0509",
	doi="10.1186/s12918-016-0288-x",
	url="http://dx.doi.org/10.1186/s12918-016-0288-x"
}

@inproceedings{scientific-benchmarking-parallel-computing-1,
	crossref={Hoefler:2015:SBP:2807591.2807644}
}
a73-hoefler.pdf

@inproceedings{Hoefler:2015:SBP:2807591.2807644,
	author = {Hoefler, Torsten and Belli, Roberto},
	title = {Scientific Benchmarking of Parallel Computing Systems: Twelve Ways to Tell the Masses when Reporting Performance Results},
	booktitle = {Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis},
	series = {SC '15},
	year = {2015},
	isbn = {978-1-4503-3723-6},
	location = {Austin, Texas},
	pages = {73:1--73:12},
	articleno = {73},
	numpages = {12},
	url = {http://doi.acm.org/10.1145/2807591.2807644},
	doi = {10.1145/2807591.2807644},
	acmid = {2807644},
	publisher = {ACM},
	address = {New York, NY, USA},
	keywords = {benchmarking, data analysis, parallel computing, statistics},
} 

@article{gropp-mpi2,
	crossref={GROPP1996789}
}
1-s2.0-0167819196000245-main.pdf

@article{GROPP1996789,
	title = "A high-performance, portable implementation of the MPI message passing interface standard",
	journal = "Parallel Computing",
	volume = "22",
	number = "6",
	pages = "789 - 828",
	year = "1996",
	note = "",
	issn = "0167-8191",
	doi = "http://dx.doi.org/10.1016/0167-8191(96)00024-5",
	url = "http://www.sciencedirect.com/science/article/pii/0167819196000245",
	author = "William Gropp and Ewing Lusk and Nathan Doss and Anthony Skjellum",
	keywords = "Message passing interface",
	keywords = "Parallel programming environment",
	keywords = "Benchmark",
	keywords = "Performance",
	keywords = "Portability",
	keywords = "MPI-2"
}

@article{gropp-parallel-io,
	crossref={Thakur01121998}
}
International Journal of High Performance Computing Applications-1998-Thakur....

@article{Thakur01121998,
	author = {Thakur, Rajeev and Lusk, Ewing and Gropp, William}, 
	title = {I/O in Parallel Applications: the Weakest Link},
	volume = {12}, 
	number = {4}, 
	pages = {389-395}, 
	year = {1998}, 
	doi = {10.1177/109434209801200401}, 
	abstract ={Parallel computers are increasingly being used to run large-scale applications that also have huge input/output (I/O) requirements. However, many applications obtain poor I/O performance on modem parallel machines. This two-part special issue of the Intemational Journal of High
	Performance Computing Applications contains papers that describe the I/O requirements and the techniques used to perform I/O in real parallel applications. The authors first explain how the I/O application program inter face (API) plays a critical role in enabling such applications to achieve high I/O performance. They describe how the commonly used UNIX I/O interface is inappropriate for parallel I/O and how an explicitly parallel API with support for collective I/O can help the underlying I/O hardware and software perform I/O efficiently. They then describe MPI- IO, a recently defined, standard, portable API specifically designed for high performance parallel I/O. They conclude with an overview of the papers in Part 1 and Part 2 of this special issue.}, 
	URL = {http://hpc.sagepub.com/content/12/4/389.abstract}, 
	eprint = {http://hpc.sagepub.com/content/12/4/389.full.pdf+html}, 
	journal = {International Journal of High Performance Computing Applications} 
}

@article{gropp-test-suite,
	crossref={Thakur2009608}
}
1-s2.0-S0167819109000143-main.pdf

@article{Thakur2009608,
title = "Test suite for evaluating performance of multithreaded \{MPI\} communication ",
journal = "Parallel Computing ",
volume = "35",
number = "12",
pages = "608 - 617",
year = "2009",
note = "Selected papers from the 14th European PVM/MPI Users Group Meeting ",
issn = "0167-8191",
doi = "http://dx.doi.org/10.1016/j.parco.2008.12.013",
url = "http://www.sciencedirect.com/science/article/pii/S0167819109000143",
author = "Rajeev Thakur and William Gropp",
keywords = "Message passing interface (MPI)",
keywords = "Multithreading",
keywords = "Performance measurement",
keywords = "Benchmarks "
}

@inproceedings{gropp-mpi-repro-perf,
	crossref={Gropp:1999:RMM:648136.748782}
}
mpptest.pdf

@inproceedings{Gropp:1999:RMM:648136.748782,
	author = {Gropp, William and Lusk, Ewing L.},
	title = {Reproducible Measurements of MPI Performance Characteristics},
	booktitle = {Proceedings of the 6th European PVM/MPI Users' Group Meeting on Recent Advances in Parallel Virtual Machine and Message Passing Interface},
	year = {1999},
	isbn = {3-540-66549-8},
	pages = {11--18},
	numpages = {8},
	url = {http://dl.acm.org/citation.cfm?id=648136.748782},
	acmid = {748782},
	publisher = {Springer-Verlag},
	address = {London, UK, UK},
} 

@article{reproducibility-benchmark-dft,
	crossref={Lejaeghereaad3000}
}
aad3000.full.pdf

@article{Lejaeghereaad3000,
	author = {Lejaeghere, Kurt and Bihlmayer, Gustav and Bj{\"o}rkman, Torbj{\"o}rn and Blaha, Peter and Bl{\"u}gel, Stefan and Blum, Volker and Caliste, Damien and Castelli, Ivano E. and Clark, Stewart J. and Dal Corso, Andrea and de Gironcoli, Stefano and Deutsch, Thierry and Dewhurst, John Kay and Di Marco, Igor and Draxl, Claudia and Du{\l}ak, Marcin and Eriksson, Olle and Flores-Livas, Jos{\'e} A. and Garrity, Kevin F. and Genovese, Luigi and Giannozzi, Paolo and Giantomassi, Matteo and Goedecker, Stefan and Gonze, Xavier and Gr{\r a}n{\"a}s, Oscar and Gross, E. K. U. and Gulans, Andris and Gygi, Fran{\c c}ois and Hamann, D. R. and Hasnip, Phil J. and Holzwarth, N. A. W. and Iu{\c s}an, Diana and Jochym, Dominik B. and Jollet, Fran{\c c}ois and Jones, Daniel and Kresse, Georg and Koepernik, Klaus and K{\"u}{\c c}{\"u}kbenli, Emine and Kvashnin, Yaroslav O. and Locht, Inka L. M. and Lubeck, Sven and Marsman, Martijn and Marzari, Nicola and Nitzsche, Ulrike and Nordstr{\"o}m, Lars and Ozaki, Taisuke and Paulatto, Lorenzo and Pickard, Chris J. and Poelmans, Ward and Probert, Matt I. J. and Refson, Keith and Richter, Manuel and Rignanese, Gian-Marco and Saha, Santanu and Scheffler, Matthias and Schlipf, Martin and Schwarz, Karlheinz and Sharma, Sangeeta and Tavazza, Francesca and Thunstr{\"o}m, Patrik and Tkatchenko, Alexandre and Torrent, Marc and Vanderbilt, David and van Setten, Michiel J. and Van Speybroeck, Veronique and Wills, John M. and Yates, Jonathan R. and Zhang, Guo-Xu and Cottenier, Stefaan},
	title = {Reproducibility in density functional theory calculations of solids},
	volume = {351},
	number = {6280},
	year = {2016},
	doi = {10.1126/science.aad3000},
	publisher = {American Association for the Advancement of Science},
	abstract = {Density functional theory (DFT) is now routinely used for simulating material properties. Many software packages are available, which makes it challenging to know which are the best to use for a specific calculation. Lejaeghere et al. compared the calculated values for the equation of states for 71 elemental crystals from 15 different widely used DFT codes employing 40 different potentials (see the Perspective by Skylaris). Although there were variations in the calculated values, most recent codes and methods converged toward a single value, with errors comparable to those of experiment.Science, this issue p. 10.1126/science.aad3000; see also p. 1394INTRODUCTIONThe reproducibility of results is one of the underlying principles of science. An observation can only be accepted by the scientific community when it can be confirmed by independent studies. However, reproducibility does not come easily. Recent works have painfully exposed cases where previous conclusions were not upheld. The scrutiny of the scientific community has also turned to research involving computer programs, finding that reproducibility depends more strongly on implementation than commonly thought. These problems are especially relevant for property predictions of crystals and molecules, which hinge on precise computer implementations of the governing equation of quantum physics.RATIONALEThis work focuses on density functional theory (DFT), a particularly popular quantum method for both academic and industrial applications. More than 15,000 DFT papers are published each year, and DFT is now increasingly used in an automated fashion to build large databases or apply multiscale techniques with limited human supervision. Therefore, the reproducibility of DFT results underlies the scientific credibility of a substantial fraction of current work in the natural and engineering sciences. A plethora of DFT computer codes are available, many of them differing considerably in their details of implementation, and each yielding a certain {\textquotedblleft}precision{\textquotedblright} relative to other codes. How is one to decide for more than a few simple cases which code predicts the correct result, and which does not? We devised a procedure to assess the precision of DFT methods and used this to demonstrate reproducibility among many of the most widely used DFT codes. The essential part of this assessment is a pairwise comparison of a wide range of methods with respect to their predictions of the equations of state of the elemental crystals. This effort required the combined expertise of a large group of code developers and expert users.RESULTSWe calculated equation-of-state data for four classes of DFT implementations, totaling 40 methods. Most codes agree very well, with pairwise differences that are comparable to those between different high-precision experiments. Even in the case of pseudization approaches, which largely depend on the atomic potentials used, a similar precision can be obtained as when using the full potential. The remaining deviations are due to subtle effects, such as specific numerical implementations or the treatment of relativistic terms.CONCLUSIONOur work demonstrates that the precision of DFT implementations can be determined, even in the absence of one absolute reference code. Although this was not the case 5 to 10 years ago, most of the commonly used codes and methods are now found to predict essentially identical results. The established precision of DFT codes not only ensures the reproducibility of DFT predictions but also puts several past and future developments on a firmer footing. Any newly developed methodology can now be tested against the benchmark to verify whether it reaches the same level of precision. New DFT applications can be shown to have used a sufficiently precise method. Moreover, high-precision DFT calculations are essential for developing improvements to DFT methodology, such as new density functionals, which may further increase the predictive power of the simulations.Recent DFT methods yield reproducible results.Whereas older DFT implementations predict different values (red darts), codes have now evolved to mutual agreement (green darts). The scoreboard illustrates the good pairwise agreement of four classes of DFT implementations (horizontal direction) with all-electron results (vertical direction). Each number reflects the average difference between the equations of state for a given pair of methods, with the green-to-red color scheme showing the range from the best to the poorest agreement.The widespread popularity of density functional theory has given rise to an extensive range of dedicated codes for predicting molecular and crystalline properties. However, each code implements the formalism in a different way, raising questions about the reproducibility of such predictions. We report the results of a community-wide effort that compared 15 solid-state codes, using 40 different potentials or basis set types, to assess the quality of the Perdew-Burke-Ernzerhof equations of state for 71 elemental crystals. We conclude that predictions from recent codes and pseudopotentials agree very well, with pairwise differences that are comparable to those between different high-precision experiments. Older methods, however, have less precise agreement. Our benchmark provides a framework for users and developers to document the precision of new applications and methodological improvements.},
	issn = {0036-8075},
	URL = {http://science.sciencemag.org/content/351/6280/aad3000},
	eprint = {http://science.sciencemag.org/content/351/6280/aad3000.full.pdf},
	journal = {Science}
}

@Inbook{Wilke2013,
author="Wilke, Jeremiah J.
and Sargsyan, Khachik
and Kenny, Joseph P.
and Debusschere, Bert
and Najm, Habib N.
and Hendry, Gilbert",
editor="Wolf, Felix
and Mohr, Bernd
and an Mey, Dieter",
title="Validation and Uncertainty Assessment of Extreme-Scale HPC Simulation through Bayesian Inference",
bookTitle="Euro-Par 2013 Parallel Processing: 19th International Conference, Aachen, Germany, August 26-30, 2013. Proceedings",
year="2013",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="41--52",
isbn="978-3-642-40047-6",
doi="10.1007/978-3-642-40047-6_7",
url="http://dx.doi.org/10.1007/978-3-642-40047-6_7"
}

@article{doi:10.1093/molbev/mss136,
author = {Pavlidis, Pavlos and Jensen, Jeffrey D. and Stephan, Wolfgang and Stamatakis, Alexandros},
title = {A Critical Assessment of Storytelling: Gene Ontology Categories and the Importance of Validating Genomic Scans},
journal = {Molecular Biology and Evolution},
volume = {29},
number = {10},
pages = {3237},
year = {2012},
doi = {10.1093/molbev/mss136},
URL = { + http://dx.doi.org/10.1093/molbev/mss136},
eprint = {/oup/backfile/Content_public/Journal/mbe/29/10/10.1093/molbev/mss136/2/mss136.pdf}
}

@article {Flouri031500,
	author = {Flouri, Tom{\'a}{\v s} and Kobert, Kassian and Rognes, Torbj{\o}rn and Stamatakis, Alexandros},
	title = {Are all global alignment algorithms and implementations correct?},
	year = {2015},
	doi = {10.1101/031500},
	publisher = {Cold Spring Harbor Labs Journals},
	abstract = {While implementing the algorithm, we discovered two mathematical mistakes in Gotoh{\textquoteright}s paper that induce sub-optimal sequence alignments. First, there are minor indexing mistakes in the dynamic programming algorithm which become apparent immediately when implementing the procedure. Hence, we report on these for the sake of completeness. Second, there is a more profound problem with the dynamic programming matrix initialization. This initialization issue can easily be missed and find its way into actual implementations. This error is also present in standard text books. Namely, the widely used books by Gusfield and Waterman. To obtain an initial estimate of the extent to which this error has been propagated, we scrutinized freely available undergraduate lecture slides. We found that 8 out of 31 lecture slides contained the mistake, while 16 out of 31 simply omit parts of the initialization, thus giving an incomplete description of the algorithm. Finally, by inspecting ten source codes and running respective tests, we found that five implementations were incorrect. Note that, not all bugs we identified are due to the mistake in Gotoh{\textquoteright}s paper. Three implementations rely on additional constraints that limit generality. Thus, only two out of ten yield correct results. We show that the error introduced by Gotoh is straightforward to resolve and provide a correct open-source reference implementation. We do believe though, that raising the awareness about these errors is critical, since the impact of incorrect pairwise sequence alignments that typically represent one of the very first stages in any bioinformatics data analysis pipeline can have a detrimental impact on downstream analyses such as multiple sequence alignment, orthology assignment, phylogenetic analyses, divergence time estimates, etc.},
	URL = {http://biorxiv.org/content/early/2015/11/12/031500},
	eprint = {http://biorxiv.org/content/early/2015/11/12/031500.full.pdf},
	journal = {bioRxiv}
}

@article {Czech035360,
	author = {Czech, Lucas and Huerta-Cepas, Jaime and Stamatakis, Alexandros},
	title = {A Critical Review on the Use of Support Values in Tree Viewers and Bioinformatics Toolkits},
	year = {2017},
	doi = {10.1101/035360},
	publisher = {Cold Spring Harbor Labs Journals},
	abstract = {Phylogenetic trees are routinely visualized to present and interpret the evolutionary relationships of species. Virtually all empirical evolutionary data studies contain a visualization of the inferred tree with branch support values. Ambiguous semantics in tree file formats can lead to erroneous tree visualizations and therefore to incorrect interpretations of phylogenetic analyses. Here, we discuss problems that can and do arise when displaying branch values on trees after re-rooting. Branch values are typically stored as node labels in the widely-used Newick tree format. However, such values are attributes of branches. Storing them as node labels can therefore yield errors when re-rooting trees. This depends on the mostly implicit semantics that tools deploy to interpret node labels. We reviewed 10 tree viewers and 10 bioinformatics toolkits that can display and re-root trees. We found that 14 out of 20 of these tools do not permit users to select the semantics of node labels. Thus, unaware users might obtain incorrect results when rooting trees inferred by common phylogenetic inference programs. We illustrate such incorrect mappings for several test cases and real examples taken from the literature. This review has already led to improvements and workarounds in 8 of the tested tools. We suggest tools should provide an option that explicitly forces users to define the semantics of node labels.},
	URL = {http://biorxiv.org/content/early/2017/01/13/035360},
	eprint = {http://biorxiv.org/content/early/2017/01/13/035360.full.pdf},
	journal = {bioRxiv}
}

@article {FokkensPostmaPedersen,
	author = {A. Fokkens and M. Erp and M. Postma and T. Pedersen and P. Vossen and N. Freire},
	title = {Offspring from Reproduction Problems: What Replication Failure Teaches Us},
	URL = {https://aclweb.org/anthology/P/P13/P13-1166.pdf}
}

@article {Darriba031930,
	author = {Darriba, Diego and Flouri, Tomas and Stamatakis, Alexandros},
	title = {The State of Software in Evolutionary Biology},
	year = {2015},
	doi = {10.1101/031930},
	publisher = {Cold Spring Harbor Labs Journals},
	abstract = {With Next Generation Sequencing Data (NGS) coming off age and being routinely used, evolutionary biology is transforming into a data-driven science. As a consequence, researchers have to rely on a growing number of increasingly complex software. All widely used tools in our field have grown considerably, in terms of the number of features as well as lines of code. In addition, analysis pipelines now include substantially more components than 5-10 years ago. A topic that has received little attention in this context is the code quality of widely used codes. Unfortunately, the majority of users tend to blindly trust software and the results it produces. To this end, we assessed the code quality of 15 highly cited tools (e.g., MrBayes, MAFFT, SweepFinder etc.) from the broader area of evolutionary biology that are used in current data analysis pipelines. We also discuss widely unknown problems associated with floating point arithmetics for representing real numbers on computer systems. Since, the software quality of the tools we analyzed is rather mediocre, we provide a list of best practices for improving the quality of existing tools, but also list techniques that can be deployed for developing reliable, high quality scientific software from scratch. Finally, we also discuss journal and science policy as well as funding issues that need to be addressed for improving software quality as well as ensuring support for developing new and maintaining existing software. Our intention is to raise the awareness of the community regarding software quality issues and to emphasize the substantial lack of funding for scientific software development.},
	URL = {http://biorxiv.org/content/early/2015/11/16/031930},
	eprint = {http://biorxiv.org/content/early/2015/11/16/031930.full.pdf},
	journal = {bioRxiv}
}

@article{sacks1989,
author = "Sacks, Jerome and Welch, William J. and Mitchell, Toby J. and Wynn, Henry P.",
doi = "10.1214/ss/1177012413",
fjournal = "Statistical Science",
journal = "Statist. Sci.",
month = "11",
number = "4",
pages = "409--423",
publisher = "The Institute of Mathematical Statistics",
title = "Design and Analysis of Computer Experiments",
url = "http://dx.doi.org/10.1214/ss/1177012413",
volume = "4",
year = "1989"
}

@article{hattoicalepcs2011,
	author = {L. Hatton},
	title = {High-Integrity Software, Computation and the Scientific Method},
	year = 2011
}

@article{leshatton-full-repro,
	author = {L. Hatton and G. Warr},
	title = {Full Computational Reproducibility in Biological Science: Methods, Software and a Case Study in Protein Biology},
	url = {https://arxiv.org/abs/1608.06897},
	year = 2016
}

@article{Monniaux:2008:PVF:1353445.1353446,
 author = {Monniaux, David},
 title = {The Pitfalls of Verifying Floating-point Computations},
 journal = {ACM Trans. Program. Lang. Syst.},
 issue_date = {May 2008},
 volume = {30},
 number = {3},
 month = may,
 year = {2008},
 issn = {0164-0925},
 pages = {12:1--12:41},
 articleno = {12},
 numpages = {41},
 url = {http://doi.acm.org/10.1145/1353445.1353446},
 doi = {10.1145/1353445.1353446},
 acmid = {1353446},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {AMD64, Abstract interpretation, Embedded software, FPU, Floating point, IA32, IEEE-754, PowerPC, Program testing, Rounding, Safety-Critical Software, Static analysis, Verification, x87},
}

@article{Thain-CMS-Repro,
  author = {Peter Ivie and Charles Zheng and Douglas Thain},
  title = {A First Look at Reproducibility and Non-Determinism in
CMS Software and ROOT Data},
  journal = {CMS Technical Report TR-2016-01},
  month = oct,
  year = {2016}
}

@techreport{MPI-Standard,
  crossref={Forum:1994:MMI:898758}
}

@techreport{Forum:1994:MMI:898758,
 author = {Forum, Message P},
 title = {MPI: A Message-Passing Interface Standard},
 year = {1994},
 source = {http://www.ncstrl.org:8900/ncstrl/servlet/search?formname=detail\&id=oai%3Ancstrlh%3Autk_cs%3Ancstrl.utk_cs%2F%2FUT-CS-94-230},
 publisher = {University of Tennessee},
 address = {Knoxville, TN, USA},
}

@article{OpenMP-Standard,
  crossref={Dagum:1998:OIA:615255.615542}
}

@article{Dagum:1998:OIA:615255.615542,
 author = {Dagum, Leonardo and Menon, Ramesh},
 title = {OpenMP: An Industry-Standard API for Shared-Memory Programming},
 journal = {IEEE Comput. Sci. Eng.},
 issue_date = {January 1998},
 volume = {5},
 number = {1},
 month = jan,
 year = {1998},
 issn = {1070-9924},
 pages = {46--55},
 numpages = {10},
 url = {http://dx.doi.org/10.1109/99.660313},
 doi = {10.1109/99.660313},
 acmid = {615542},
 publisher = {IEEE Computer Society Press},
 address = {Los Alamitos, CA, USA},
}

@inproceedings{DEPEND-Resiliance,
  crossref={7266835}
}

@INPROCEEDINGS{7266835,
author={C. D. Martino and W. Kramer and Z. Kalbarczyk and R. Iyer},
booktitle={2015 45th Annual IEEE/IFIP International Conference on Dependable Systems and Networks},
title={Measuring and Understanding Extreme-Scale Application Resilience: A Field Study of 5,000,000 HPC Application Runs},
year={2015},
pages={25-36},
keywords={Cray computers;failure analysis;parallel machines;parallel processing;system monitoring;system recovery;Blue Waters;Cray hybrid supercomputer;HPC application runs;LogDiver;application failure probability;error-failure logs;extreme-scale application resilience;system errors;system failures;workload logs;Blades;Graphics processing units;Hardware;Random access memory;Servers;Torque;Xenon;application resilience;data analysis;data-driven resilience;extreme-scale;hybrid machines;resilience;supercomputer},
doi={10.1109/DSN.2015.50},
ISSN={1530-0889},
month={June},
}

@article{Enzo,
 crossref={2014ApJS..211...19B}
}

@ARTICLE{2014ApJS..211...19B,
   author = {{Bryan}, G.~L. and {Norman}, M.~L. and {O'Shea}, B.~W. and {Abel}, T. and
   {Wise}, J.~H. and {Turk}, M.~J. and {Reynolds}, D.~R. and {Collins}, D.~C. and
   {Wang}, P. and {Skillman}, S.~W. and {Smith}, B. and {Harkness}, R.~P. and
   {Bordner}, J. and {Kim}, J.-h. and {Kuhlen}, M. and {Xu}, H. and
   {Goldbaum}, N. and {Hummels}, C. and {Kritsuk}, A.~G. and {Tasker}, E. and
   {Skory}, S. and {Simpson}, C.~M. and {Hahn}, O. and {Oishi}, J.~S. and
   {So}, G.~C. and {Zhao}, F. and {Cen}, R. and {Li}, Y. and {The Enzo Collaboration}
   },
    title = "{ENZO: An Adaptive Mesh Refinement Code for Astrophysics}",
  journal = {\apjs},
archivePrefix = "arXiv",
   eprint = {1307.2265},
 primaryClass = "astro-ph.IM",
 keywords = {hydrodynamics, methods: numerical },
     year = 2014,
    month = apr,
   volume = 211,
      eid = {19},
    pages = {19},
      doi = {10.1088/0067-0049/211/2/19},
   adsurl = {http://adsabs.harvard.edu/abs/2014ApJS..211...19B},
  adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@article{AGORA-II,
  crossref={0004-637X-833-2-202},
}

@article{0004-637X-833-2-202,
  author={Ji-hoon Kim and Oscar Agertz and Romain Teyssier and Michael J. Butler and Daniel Ceverino and Jun-Hwan Choi and Robert
Feldmann and Ben W. Keller and Alessandro Lupi and Thomas Quinn and Yves Revaz and Spencer Wallace and Nickolay Y.
Gnedin and Samuel N. Leitner and Sijing Shen and Britton D. Smith and Robert Thompson and Matthew J. Turk and Tom Abel and Kenza
S. Arraki and Samantha M. Benincasa and Sukanya Chakrabarti and Colin DeGraf and Avishai Dekel and Nathan J.
Goldbaum and Philip F. Hopkins and Cameron B. Hummels and Anatoly Klypin and Hui Li and Piero Madau and Nir Mandelker and Lucio
Mayer and Kentaro Nagamine and Sarah Nickerson and Brian W. O’Shea and Joel R. Primack and Santi Roca-Fàbrega and Vadim
Semenov and Ikkoh Shimizu and Christine M. Simpson and Keita Todoroki and James W. Wadsley and John H. Wise and  AGORA
Collaboration},
  title={The AGORA High-resolution Galaxy Simulations Comparison Project. II. Isolated Disk Test},
  journal={The Astrophysical Journal},
  volume={833},
  number={2},
  pages={202},
  url={http://stacks.iop.org/0004-637X/833/i=2/a=202},
  year={2016},
  abstract={Using an isolated Milky Way-mass galaxy simulation, we compare results from nine state-of-the-art gravito-hydrodynamics codes widely used in the numerical community. We utilize the infrastructure we have built for the AGORA High-resolution Galaxy Simulations Comparison Project. This includes the common disk initial conditions, common physics models (e.g., radiative cooling and UV background by the standardized package Grackle ) and common analysis toolkit yt , all of which are publicly available. Subgrid physics models such as Jeans pressure floor, star formation, supernova feedback energy, and metal production are carefully constrained across code platforms. With numerical accuracy that resolves the disk scale height, we find that the codes overall agree well with one another in many dimensions including: gas and stellar surface densities, rotation curves, velocity dispersions, density and temperature distribution functions, disk vertical heights, stellar clumps, star formation rates, and Kennicutt–Schmidt relations. Quantities such as velocity dispersions are very robust (agreement within a few tens of percent at all radii) while measures like newly formed stellar clump mass functions show more significant variation (difference by up to a factor of ∼3). Systematic differences exist, for example, between mesh-based and particle-based codes in the low-density region, and between more diffusive and less diffusive schemes in the high-density tail of the density distribution. Yet intrinsic code differences are generally small compared to the variations in numerical implementations of the common subgrid physics such as supernova feedback. Our experiment reassures that, if adequately designed in accordance with our proposed common parameters, results of a modern high-resolution galaxy formation simulation are more sensitive to input physics than to intrinsic differences in numerical schemes.}
}

@article{rockstar,
  crossref={0004-637X-762-2-109}
}

@article{0004-637X-762-2-109,
  author={Peter S. Behroozi and Risa H. Wechsler and Hao-Yi Wu},
  title={The ROCKSTAR Phase-space Temporal Halo Finder and the Velocity Offsets of Cluster Cores},
  journal={The Astrophysical Journal},
  volume={762},
  number={2},
  pages={109},
  url={http://stacks.iop.org/0004-637X/762/i=2/a=109},
  year={2013},
  abstract={We present a new algorithm for identifying dark matter halos, substructure, and tidal features. The approach is based on adaptive hierarchical refinement of friends-of-friends groups in six phase-space dimensions and one time dimension, which allows for robust (grid-independent, shape-independent, and noise-resilient) tracking of substructure; as such, it is named ROCKSTAR (Robust Overdensity Calculation using K-Space Topologically Adaptive Refinement). Our method is massively parallel (up to 10 5 CPUs) and runs on the largest current simulations (>10 10 particles) with high efficiency (10 CPU hours and 60 gigabytes of memory required per billion particles analyzed). A previous paper has shown ROCKSTAR to have excellent recovery of halo properties; we expand on these comparisons with more tests and higher-resolution simulations. We show a significant improvement in substructure recovery compared to several other halo finders and discuss the theoretical and practical limits of simulations in this regard. Finally, we present results that demonstrate conclusively that dark matter halo cores are not at rest relative to the halo bulk or substructure average velocities and have coherent velocity offsets across a wide range of halo masses and redshifts. For massive clusters, these offsets can be up to 350 km s –1 at z = 0 and even higher at high redshifts. Our implementation is publicly available at http://code.google.com/p/rockstar [http://code.google.com/p/rockstar] .}
}

@inproceedings{Spack,
  crossref={Gamblin:2015:SPM:2807591.2807623}
}

@inproceedings{Gamblin:2015:SPM:2807591.2807623,
 author = {Gamblin, Todd and LeGendre, Matthew and Collette, Michael R. and Lee, Gregory L. and Moody, Adam and de Supinski, Bronis R. and Futral, Scott},
 title = {The Spack Package Manager: Bringing Order to HPC Software Chaos},
 booktitle = {Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis},
 series = {SC '15},
 year = {2015},
 isbn = {978-1-4503-3723-6},
 location = {Austin, Texas},
 pages = {40:1--40:12},
 articleno = {40},
 numpages = {12},
 url = {http://doi.acm.org/10.1145/2807591.2807623},
 doi = {10.1145/2807591.2807623},
 acmid = {2807623},
 publisher = {ACM},
 address = {New York, NY, USA},
}

@ONLINE{hdf5,
    author = {{The HDF Group}},
    title = "{Hierarchical data format version 5}",
    year = {2000-2010},
    url = {http://www.hdfgroup.org/HDF5}
}

@article{yt,
  crossref={2011ApJS..192....9T}
}

@ARTICLE{2011ApJS..192....9T,
   author = {{Turk}, M.~J. and {Smith}, B.~D. and {Oishi}, J.~S. and {Skory}, S. and
	{Skillman}, S.~W. and {Abel}, T. and {Norman}, M.~L.},
    title = "{yt: A Multi-code Analysis Toolkit for Astrophysical Simulation Data}",
  journal = {\apjs},
archivePrefix = "arXiv",
   eprint = {1011.3514},
 primaryClass = "astro-ph.IM",
 keywords = {cosmology: theory, methods: data analysis, methods: numerical},
     year = 2011,
    month = jan,
   volume = 192,
      eid = {9},
    pages = {9},
      doi = {10.1088/0067-0049/192/1/9},
   adsurl = {http://adsabs.harvard.edu/abs/2011ApJS..192....9T},
  adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@article {Stodden1240,
	author = {Stodden, Victoria and McNutt, Marcia and Bailey, David H. and Deelman, Ewa and Gil, Yolanda and Hanson, Brooks and Heroux, Michael A. and Ioannidis, John P.A. and Taufer, Michela},
	title = {Enhancing reproducibility for computational methods},
	volume = {354},
	number = {6317},
	pages = {1240--1241},
	year = {2016},
	doi = {10.1126/science.aah6168},
	publisher = {American Association for the Advancement of Science},
	issn = {0036-8075},
	URL = {http://science.sciencemag.org/content/354/6317/1240},
	eprint = {http://science.sciencemag.org/content/354/6317/1240.full.pdf},
	journal = {Science}
}

@article {Barba142,
	author = {Barba, Lorena A.},
	title = {The hard road to reproducibility},
	volume = {354},
	number = {6308},
	pages = {142--142},
	year = {2016},
	doi = {10.1126/science.354.6308.142},
	publisher = {American Association for the Advancement of Science},
	issn = {0036-8075},
	URL = {http://science.sciencemag.org/content/354/6308/142},
	eprint = {http://science.sciencemag.org/content/354/6308/142.full.pdf},
	journal = {Science}
}

@Article{ContainersNature,
	author={Silver A.},
	title={Software simplified},
	journal={Nature},
	year={2017},
	month={May},
	publisher={Nature Publishing Group},
	volume={546},
	pages={173-174},
	doi={10.1038/546173a},
	url={http://dx.doi.org/546173a}
}

@article{10.1371/journal.pone.0038234,
    author = {Gronenschild, Ed H. B. M. AND Habets, Petra AND Jacobs, Heidi I. L. AND Mengelers, Ron AND Rozendaal, Nico AND van Os, Jim AND Marcelis, Machteld},
    journal = {PLOS ONE},
    publisher = {Public Library of Science},
    title = {The Effects of FreeSurfer Version, Workstation Type, and Macintosh Operating System Version on Anatomical Volume and Cortical Thickness Measurements},
    year = {2012},
    month = {06},
    volume = {7},
    url = {https://doi.org/10.1371/journal.pone.0038234},
    pages = {1-13},
    abstract = {FreeSurfer is a popular software package to measure cortical thickness and volume of neuroanatomical structures. However, little if any is known about measurement reliability across various data processing conditions. Using a set of 30 anatomical T1-weighted 3T MRI scans, we investigated the effects of data processing variables such as FreeSurfer version (v4.3.1, v4.5.0, and v5.0.0), workstation (Macintosh and Hewlett-Packard), and Macintosh operating system version (OSX 10.5 and OSX 10.6). Significant differences were revealed between FreeSurfer version v5.0.0 and the two earlier versions. These differences were on average 8.8±6.6\% (range 1.3–64.0\%) (volume) and 2.8±1.3\% (1.1–7.7\%) (cortical thickness). About a factor two smaller differences were detected between Macintosh and Hewlett-Packard workstations and between OSX 10.5 and OSX 10.6. The observed differences are similar in magnitude as effect sizes reported in accuracy evaluations and neurodegenerative studies. The main conclusion is that in the context of an ongoing study, users are discouraged to update to a new major release of either FreeSurfer or operating system or to switch to a different type of workstation without repeating the analysis; results thus give a quantitative support to successive recommendations stated by FreeSurfer developers over the years. Moreover, in view of the large and significant cross-version differences, it is concluded that formal assessment of the accuracy of FreeSurfer is desirable.},
    number = {6},
    doi = {10.1371/journal.pone.0038234}
}

@article{doi:10.1001/jama.294.2.218,
author = {Ioannidis JA},
title = {Contradicted and initially stronger effects in highly cited clinical
research},
journal = {JAMA},
volume = {294},
number = {2},
pages = {218-228},
year = {2005},
doi = {10.1001/jama.294.2.218},
URL = { + http://dx.doi.org/10.1001/jama.294.2.218},
eprint = {/data/journals/jama/4983/joc50060.pdf}
}

@article{10.1371/journal.pmed.0020124,
    author = {Ioannidis, John P. A.},
    journal = {PLOS Medicine},
    publisher = {Public Library of Science},
    title = {Why Most Published Research Findings Are False},
    year = {2005},
    month = {08},
    volume = {2},
    url = {https://doi.org/10.1371/journal.pmed.0020124},
    pages = {},
    abstract = {Published research findings are sometimes refuted by subsequent evidence, says Ioannidis, with ensuing confusion and disappointment.},
    number = {8},
    doi = {10.1371/journal.pmed.0020124}
}

@article {aac4716,
	author = {Open Science Collaboration},
	title = {Estimating the reproducibility of psychological science},
	volume = {349},
	number = {6251},
	year = {2015},
	doi = {10.1126/science.aac4716},
	publisher = {American Association for the Advancement of Science},
	abstract = {One of the central goals in any scientific endeavor is to understand causality. Experiments that seek to demonstrate a cause/effect relation most often manipulate the postulated causal factor. Aarts et al. describe the replication of 100 experiments reported in papers published in 2008 in three high-ranking psychology journals. Assessing whether the replication and the original experiment yielded the same result according to several criteria, they find that about one-third to one-half of the original findings were also observed in the replication study.Science, this issue 10.1126/science.aac4716INTRODUCTIONReproducibility is a defining feature of science, but the extent to which it characterizes current research is unknown. Scientific claims should not gain credence because of the status or authority of their originator but by the replicability of their supporting evidence. Even research of exemplary quality may have irreproducible empirical findings because of random or systematic error.RATIONALEThere is concern about the rate and predictors of reproducibility, but limited evidence. Potentially problematic practices include selective reporting, selective analysis, and insufficient specification of the conditions necessary or sufficient to obtain the results. Direct replication is the attempt to recreate the conditions believed sufficient for obtaining a previously observed finding and is the means of establishing reproducibility of a finding with new data. We conducted a large-scale, collaborative effort to obtain an initial estimate of the reproducibility of psychological science.RESULTSWe conducted replications of 100 experimental and correlational studies published in three psychology journals using high-powered designs and original materials when available. There is no single standard for evaluating replication success. Here, we evaluated reproducibility using significance and P values, effect sizes, subjective assessments of replication teams, and meta-analysis of effect sizes. The mean effect size (r) of the replication effects (Mr = 0.197, SD = 0.257) was half the magnitude of the mean effect size of the original effects (Mr = 0.403, SD = 0.188), representing a substantial decline. Ninety-seven percent of original studies had significant results (P \&lt; .05). Thirty-six percent of replications had significant results; 47\% of original effect sizes were in the 95\% confidence interval of the replication effect size; 39\% of effects were subjectively rated to have replicated the original result; and if no bias in original results is assumed, combining original and replication results left 68\% with statistically significant effects. Correlational tests suggest that replication success was better predicted by the strength of original evidence than by characteristics of the original and replication teams.CONCLUSIONNo single indicator sufficiently describes replication success, and the five indicators examined here are not the only ways to evaluate reproducibility. Nonetheless, collectively these results offer a clear conclusion: A large portion of replications produced weaker evidence for the original findings despite using materials provided by the original authors, review in advance for methodological fidelity, and high statistical power to detect the original effect sizes. Moreover, correlational evidence is consistent with the conclusion that variation in the strength of initial evidence (such as original P value) was more predictive of replication success than variation in the characteristics of the teams conducting the research (such as experience and expertise). The latter factors certainly can influence replication success, but they did not appear to do so here.Reproducibility is not well understood because the incentives for individual scientists prioritize novelty over replication. Innovation is the engine of discovery and is vital for a productive, effective scientific enterprise. However, innovative ideas become old news fast. Journal reviewers and editors may dismiss a new test of a published idea as unoriginal. The claim that {\textquotedblleft}we already know this{\textquotedblright} belies the uncertainty of scientific evidence. Innovation points out paths that are possible; replication points out paths that are likely; progress relies on both. Replication can increase certainty when findings are reproduced and promote innovation when they are not. This project provides accumulating evidence for many findings in psychological research and suggests that there is still more work to do to verify whether we know what we think we know.Original study effect size versus replication effect size (correlation coefficients).Diagonal line represents replication effect size equal to original effect size. Dotted line represents replication effect size of 0. Points below the dotted line were effects in the opposite direction of the original. Density plots are separated by significant (blue) and nonsignificant (red) effects.Reproducibility is a defining feature of science, but the extent to which it characterizes current research is unknown. We conducted replications of 100 experimental and correlational studies published in three psychology journals using high-powered designs and original materials when available. Replication effects were half the magnitude of original effects, representing a substantial decline. Ninety-seven percent of original studies had statistically significant results. Thirty-six percent of replications had statistically significant results; 47\% of original effect sizes were in the 95\% confidence interval of the replication effect size; 39\% of effects were subjectively rated to have replicated the original result; and if no bias in original results is assumed, combining original and replication results left 68\% with statistically significant effects. Correlational tests suggest that replication success was better predicted by the strength of original evidence than by characteristics of the original and replication teams.},
	issn = {0036-8075},
	URL = {http://science.sciencemag.org/content/349/6251/aac4716},
	eprint = {http://science.sciencemag.org/content/349/6251/aac4716.full.pdf},
	journal = {Science}
}
aac4716.full.pdf

@article{Begley2012,
	author={"Begley, C. Glenn and Ellis, Lee M."},
	title={"Drug development: Raise standards for preclinical cancer research"},
	journal={Nature},
	year={2012},
	month={"Mar"},
	day={"29"},
	publisher={"Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved."},
	volume={"483"},
	number={"7391"},
	pages={"531--533"},
	issn={"0028-0836"},
	doi={"10.1038/483531a"},
	url={"http://dx.doi.org/10.1038/483531a"}
}

@article{Baker2016,
	author={Baker, Monya},
	title={1,500 scientists lift the lid on reproducibility},
	journal={Nature},
	year={2016},
	month={May},
	day={26},
	publisher={Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
	volume={533},
	pages={452--454},
	doi={10.1038/533452a}
}

@article{Begley116,
	author = {Begley, C. Glenn and Ioannidis, John P.A.},
	title = {Reproducibility in Science},
	volume = {116},
	number = {1},
	pages = {116--126},
	year = {2014},
	doi = {10.1161/CIRCRESAHA.114.303819},
	publisher = {American Heart Association, Inc.},
	abstract = {Medical and scientific advances are predicated on new knowledge that is robust and reliable and that serves as a solid foundation on which further advances can be built. In biomedical research, we are in the midst of a revolution with the generation of new data and scientific publications at a previously unprecedented rate. However, unfortunately, there is compelling evidence that the majority of these discoveries will not stand the test of time. To a large extent, this reproducibility crisis in basic and preclinical research may be as a result of failure to adhere to good scientific practice and the desperation to publish or perish. This is a multifaceted, multistakeholder problem. No single party is solely responsible, and no single solution will suffice. Here we review the reproducibility problems in basic and preclinical biomedical research, highlight some of the complexities, and discuss potential solutions that may help improve research quality and reproducibility.},
	issn = {0009-7330},
	URL = {http://circres.ahajournals.org/content/116/1/116},
	eprint = {http://circres.ahajournals.org/content/116/1/116.full.pdf},
	journal = {Circulation Research}
}

@misc{stodden-computational-science-talk,
	author={Stodden, Victoria},
	title={How Computational Science is Changing the Scientific Method},
	year={2009},
	month={July},
	day={29},
	url = {https://web.stanford.edu/~vcs/talks/Science20July2009VictoriaStodden.pdf}
}

@misc{acm-badging,
	title={Artifact Review and Badging},
	url = {https://www.acm.org/publications/policies/artifact-review-badging}
}

@inproceedings{clusterjob,
	crossref={7840870}
}

@INPROCEEDINGS{7840870, 
	author={H. Monajemi and D. L. Donoho and V. Stodden}, 
	booktitle={2016 IEEE International Conference on Big Data (Big Data)}, 
	title={Making massive computational experiments painless}, 
	year={2016}, 
	pages={2368-2373}, 
	keywords={cloud computing;data analysis;pattern clustering;public domain software;CJ;ClusterJob;cloud-based paradigms;cluster exploitation;code publication;computational workflow;data analysis;data reporting;data scientist;disparate disconnected tools;error ubiquity;experiment design end-to-end process;job management;large-scale computing clusters;massive computational experimentation;million-CPU-hour experiments;output harvesting;scientific computation;Big data;Cloud computing;Computational modeling;Electronic mail;MATLAB;Measurement;Scientific computing;Big Data;High-throughput Computing;Reproducible Research}, 
	doi={10.1109/BigData.2016.7840870}, 
	month={Dec},
}

@incollection{stodden-legal,
	author={Victoria Stodden},
	title={What Computational Scientists Need to Know About Intellectual Property Law: A Primer},
	booktitle={Implementing Reproducible Research},
	publisher={Chapman and Hall/CRC},
	year={2014},
	month={April},
	day={14},
	url={https://web.stanford.edu/~vcs/papers/IRR-Stodden_chapter.pdf}
}

@article{Collberg:2016:RCS:2897191.2812803,
 author = {Collberg, Christian and Proebsting, Todd A.},
 title = {Repeatability in Computer Systems Research},
 journal = {Commun. ACM},
 issue_date = {March 2016},
 volume = {59},
 number = {3},
 month = feb,
 year = {2016},
 issn = {0001-0782},
 pages = {62--69},
 numpages = {8},
 url = {http://doi.acm.org/10.1145/2812803},
 doi = {10.1145/2812803},
 acmid = {2812803},
 publisher = {ACM},
 address = {New York, NY, USA},
} 

@inproceedings{reprozip,
	crossref={Chirigati:2016:RCR:2882903.2899401}
}
@inproceedings{Chirigati:2016:RCR:2882903.2899401,
 author = {Chirigati, Fernando and Rampin, R{\'e}mi and Shasha, Dennis and Freire, Juliana},
 title = {ReproZip: Computational Reproducibility With Ease},
 booktitle = {Proceedings of the 2016 International Conference on Management of Data},
 series = {SIGMOD '16},
 year = {2016},
 isbn = {978-1-4503-3531-7},
 location = {San Francisco, California, USA},
 pages = {2085--2088},
 numpages = {4},
 url = {http://doi.acm.org/10.1145/2882903.2899401},
 doi = {10.1145/2882903.2899401},
 acmid = {2899401},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {computational reproducibility, provenance, reprozip},
} 

@misc{reproducible-builds,
	title = {reproducible-builds.org},
	url = {https://reproducible-builds.org/}
}

@article{sciunits,
	author = {Dai Hai Ton That and Gabriel Fils and Zhihao Yuan and Tanu Malik},
	title = {Sciunits: Reusable Research Objects},
	year = {2017},
	url = {https://arxiv.org/abs/1707.05731}
}

@article{economics-replicability-fed,
	author = {Andrew C. Chang and Phillip Li},
	title = {Is Economics Research Replicable? Sixty Published Papers from
Thirteen Journals Say ”Usually Not”},
	year = {2015},
	doi = {10.17016/FEDS.2015.083},
	booktitle = {Finance and Economics Discussion
Series 2015-083},
	publisher = {Washington: Board of Governors of the Federal Reserve System}
}

@misc {computer-physics-communications,
	title = {Computer Physics Communications},
	url = {https://www.journals.elsevier.com/computer-physics-communications/}
}

@misc {darpa-open-catalog,
	title = {DARPA Open Catalog},
	url = {https://opencatalog.darpa.mil/}
}

@misc {doe-code,
	title = {DOE Code},
	url = {https://www.osti.gov/doecode/}
}

@misc {elsevier-mendeley-computer-physics-communications,
	title = {Mendeley data repository for Comptuter Physics Communications},
	url = {https://data.mendeley.com/datasets/journals/00104655}
}

@book {code-complete,
	author = {Steve McConnell},
	title = {Code Complete},
	year = {2004}
}

@technreport{ISO-9126,
	type = {Standard},
	key = {ISO 25010:2011},
	year = {2011},
	month = {March},
	day = {1},
	title = {Software Engineering -- Product Quality}
}

@article{doi:10.1093/aje/kwj093,
  author = {Peng, Roger D. and Dominici, Francesca and Zeger, Scott L.},
  title = {Reproducible Epidemiologic Research},
  journal = {American Journal of Epidemiology},
  volume = {163},
  number = {9},
  pages = {783-789},
  year = {2006},
  doi = {10.1093/aje/kwj093},
  URL = {http://dx.doi.org/10.1093/aje/kwj093},
  eprint = {/oup/backfile/content_public/journal/aje/163/9/10.1093/aje/kwj093/2/kwj093.pdf}
}

@Inbook{Buckheit1995,
  author="Buckheit, Jonathan B.
  and Donoho, David L.",
  editor="Antoniadis, Anestis
  and Oppenheim, Georges",
  title="WaveLab and Reproducible Research",
  bookTitle="Wavelets and Statistics",
  year="1995",
  publisher="Springer New York",
  address="New York, NY",
  pages="55--81",
  abstract="Wavelab is a library of wavelet-packet analysis, cosine-packet analysis and matching pursuit. The library is available free of charge over the Internet. Versions are provided for Macintosh, UNIX and Windows machines.",
  isbn="978-1-4612-2544-7",
  doi="10.1007/978-1-4612-2544-7_5",
  url="https://doi.org/10.1007/978-1-4612-2544-7_5"
}

@misc{claerbout-reproducibility-website,
	title = {REPRODUCIBLE COMPUTATIONAL RESEARCH: A history of hurdles, mostly overcome},
	url={http://sepwww.stanford.edu/sep/jon/reproducible.html}
}

@misc{neuromorphic-chips-webarticle,
	title = {Neuromorphic Chips Are Destined for Deep Learning—or Obscurity},
	url={http://spectrum.ieee.org/semiconductors/design/neuromorphic-chips-are-destined-for-deep-learningor-obscurity}
}

@article {King95,
	title = {Replication, Replication},
	journal = {PS: Political Science and Politics},
	volume = {28},
	year = {1995},
	note = {See updates to this paper\&nbsp;for how I use this paper as a class assignment now.},
	month = {September},
	pages = {444-452},
	abstract = {Political science is a community enterprise and the community of empirical political scientists need access to the body of data necessary to replicate existing studies to understand, evaluate, and especially build on this work. Unfortunately, the norms we have in place now do not encourage, or in some cases even permit, this aim. Following are suggestions that would facilitate replication and are easy to implement {\textendash} by teachers, students, dissertation writers, graduate programs, authors, reviewers, funding agencies, and journal and book editors.},
	author = {Gary King}
}

@inproceedings{elec-doc-res-new-meaning,
	title={Electronic documents give reproducible research a new meaning},
	author={Jon F. Claerbout and Martin Karrenbach},
	booktitle={SEG Technical Program Expanded Abstracts},
	year={1992},
	pages = {601-604},
	doi = {10.1190/1.1822162},
	url = {http://sepwww.stanford.edu/doku.php?id=sep:research:reproducible:seg92}
}

@article{doi:10.1109/MCSE.2009.14,
  author = {Sergey Fomel and Jon F. Claerbout},
  title = {Reproducible Research},
  journal = {Computing in Science \& Engineering},
  volume = {11},
  number = {1},
  pages = {5-7},
  year = {2009},
  doi = {10.1109/MCSE.2009.14},
  URL = { http://aip.scitation.org/doi/abs/10.1109/MCSE.2009.14 },
  eprint = { http://aip.scitation.org/doi/pdf/10.1109/MCSE.2009.14 },
  abstract = { Reproducibility is a core principle of science. For computational experiments to become reproducible, one needs to develop a system for linking scientific publications with computational recipes. Articles in this special issue argue in favor of computational reproducibility and describe several practical approaches to reproducible research. }
}

@ARTICLE{ThreeDreams, 
  author={M. Gavish and D. Donoho}, 
  journal={Computing in Science Engineering}, 
  title={Three Dream Applications of Verifiable Computational Results}, 
  year={2012}, 
  volume={14}, 
  number={4}, 
  pages={26-31}, 
  keywords={Web services;formal verification;medical computing;VCR;computer-based research;dream applications;permanent Web services;verifiable computational results;Computer applications;Formal verification;Programming;Reproducibility of results;Research and development;Scientific computing;Video recording;Computer applications;Formal verification;Programming;RESTful Web services;Reproducibility of results;Research and development;Scientific computing;VCR;Video recording;dream applications;meta-analysis;repository;reproducible research;scientific computing;verifiable research;verifiable result identifier}, 
  doi={10.1109/MCSE.2012.65}, 
  ISSN={1521-9615}, 
  month={July},
}

@INPROCEEDINGS{TranslationOpenMPOpenACC, 
  author={S. Pino and L. Pollock and S. Chandrasekaran}, 
  booktitle={2017 IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW)}, 
  title={Exploring Translation of OpenMP to OpenACC 2.5: Lessons Learned}, 
  year={2017}, 
  pages={673-682}, 
  keywords={Benchmark testing;Computational modeling;Computer architecture;Graphics processing units;Hardware;Programming;GPU;Multicore;OpenACC;OpenMP;Translation}, 
  doi={10.1109/IPDPSW.2017.84}, 
  month={May}
}

@article{ProgressIn10Years,
	author={P. Ginsparg},
	title={Next-Generation Implications of Open Access},
	journal={CTWatch Quarterly},
	volume={3},
	number={3},
	year={2007},
	month={August},
	url={http://www.ctwatch.org/quarterly/articles/2007/08/next-generation-implications-of-open-access/}
}

@INPROCEEDINGS{computational-meta-data, 
  author={P. Thavasimani and P. Missier}, 
  booktitle={2016 IEEE International Conference on Big Data (Big Data)}, 
  title={Facilitating reproducible research by investigating computational metadata}, 
  year={2016}, 
  pages={3045-3051}, 
  keywords={meta data;NoWorkflow;YesWorkflow;changed artifacts;computational metadata;computational workflows;reproducibility;reproducible research;Big data;Cloud computing;Computational modeling;Data visualization;Hardware;Metadata;Metadata;NoWorkflow;Reproducibility;Why-Diff;YesWorkflow}, 
  doi={10.1109/BigData.2016.7840958}, 
  month={Dec}
}

@inproceedings{FRAPpuccino,
  author = {Xueyuan Han and Thomas Pasquier and Tanvi Ranjan and Mark Goldstein and Margo Seltzer},
  title = {FRAPpuccino: Fault-detection through Runtime Analysis of Provenance},
  booktitle = {9th {USENIX} Workshop on Hot Topics in Cloud Computing (HotCloud 17)},
  year = {2017},
  address = {Santa Clara, CA},
  url = {https://www.usenix.org/conference/hotcloud17/program/presentation/han},
  publisher = {{USENIX} Association},
}

@inproceedings{blame-analysis,
 author = {Rubio-Gonz\'{a}lez, Cindy and Nguyen, Cuong and Mehne, Benjamin and Sen, Koushik and Demmel, James and Kahan, William and Iancu, Costin and Lavrijsen, Wim and Bailey, David H. and Hough, David},
 title = {Floating-point Precision Tuning Using Blame Analysis},
 booktitle = {Proceedings of the 38th International Conference on Software Engineering},
 series = {ICSE '16},
 year = {2016},
 isbn = {978-1-4503-3900-1},
 location = {Austin, Texas},
 pages = {1074--1085},
 numpages = {12},
 url = {http://doi.acm.org/10.1145/2884781.2884850},
 doi = {10.1145/2884781.2884850},
 acmid = {2884850},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {floating point, mixed precision, program optimization},
}

@ARTICLE{high-precision-arith-in-science, 
  author={D. H. Bailey}, 
  journal={Computing in Science Engineering}, 
  title={High-precision floating-point arithmetic in scientific computation}, 
  year={2005}, 
  volume={7}, 
  number={3}, 
  pages={54-61}, 
  keywords={IEEE standards;floating point arithmetic;natural sciences computing;software packages;IEEE 64-bit floating-point arithmetic;high-precision floating-point arithmetic;numeric precision;program design;scientific computation;Application software;Floating-point arithmetic;High level languages;High performance computing;Mathematics;Packaging;Personal communication networks;Software algorithms;Software packages;Software performance;climate modeling;computational chemistry;computational physics;experimental mathematics;high-precision arithmetic;quantum theory}, 
  doi={10.1109/MCSE.2005.52}, 
  ISSN={1521-9615}, 
  month={May},
}

@misc{mpfun,
  author={David H. Bailey},
  title={A Thread-Safe Arbitrary Precision
Computation Package},
  url={http://www.davidhbailey.com/dhbpapers/mpfun2015.pdf}
}

@misc{david-bailey-site,
  author={David H. Bailey},
  title={David H Bailey},
  url={http://davidhbailey.com/}
}

@misc{dhb-zurich-hp,
  author={David H. Bailey},
  title={Petascale computing and high-precision arithmetic: Applications and challenges},
  year={2015},
  month={Mar},
  day={26},
  url={http://www.davidhbailey.com/dhbtalks/dhb-zurich-hp.pdf},
}

@article{acm-badging-announcement,
 author = {Boisvert, Ronald F.},
 title = {Incentivizing Reproducibility},
 journal = {Commun. ACM},
 issue_date = {October 2016},
 volume = {59},
 number = {10},
 month = sep,
 year = {2016},
 issn = {0001-0782},
 pages = {5--5},
 numpages = {1},
 url = {http://doi.acm.org/10.1145/2994031},
 doi = {10.1145/2994031},
 acmid = {2994031},
 publisher = {ACM},
 address = {New York, NY, USA},
} 

@Article{sighpc-connect-repro-1,
 editor = {Vuduc, Rich},
 journal = {ACM SIGHPC Connect},
 year = {2016},
 volume = {5},
 number = {1},
 issue_date = {October 2016},
 publisher = {ACM},
 address = {New York, NY, USA},
}

@Article{sighpc-connect-repro-2,
 editor = {Vuduc, Rich},
 journal = {ACM SIGHPC Connect},
 year = {2017},
 volume = {5},
 number = {2},
 issue_date = {February 2017},
 publisher = {ACM},
 address = {New York, NY, USA},
}

@article{doi:10.1080/01621459.1972.10481279,
  author = { David F.   Bauer },
  title = {Constructing Confidence Sets Using Rank Statistics},
  journal = {Journal of the American Statistical Association},
  volume = {67},
  number = {339},
  pages = {687-690},
  year = {1972},
  doi = {10.1080/01621459.1972.10481279},
  URL = { http://amstat.tandfonline.com/doi/abs/10.1080/01621459.1972.10481279 },
  eprint = { http://amstat.tandfonline.com/doi/pdf/10.1080/01621459.1972.10481279}
}

@article{10.2307/2984263,
 ISSN = {00359246},
 URL = {http://www.jstor.org/stable/2984263},
 abstract = {The use of Monte Carlo test procedures for significance testing, with smaller reference sets than are now generally used, is advocated. It is shown that, for given α = 1/n, n a positive integer, the power of the Monte Carlo test procedure is a monotone increasing function of the size of the reference set, the limit of which is the power of the corresponding uniformly most powerful test. The power functions and efficiency of the Monte Carlo test to the uniformly most powerful test are discussed in detail for the case where the test criterion is N(γ. 1). The cases when the test criterion is Student's t-statistic and when the test statistic is exponentially distributed are considered also.},
 author = {Adery C. A. Hope},
 journal = {Journal of the Royal Statistical Society. Series B (Methodological)},
 number = {3},
 pages = {582-598},
 publisher = {[Royal Statistical Society, Wiley]},
 title = {A Simplified Monte Carlo Significance Test Procedure},
 volume = {30},
 year = {1968}
}

@misc{R-wilcoxon-test,
  title={Wilcoxon Rank Sum and Signed Rank Tests},
  url={https://stat.ethz.ch/R-manual/R-devel/library/stats/html/wilcox.test.html}
}

@misc{R-pearson-chisquare,
  title={Pearson's Chi-squared Test for Count Data},
  url={https://stat.ethz.ch/R-manual/R-devel/library/stats/html/chisq.test.html}
}

@article{stodden-reproducibility-scientific-method,
  author={Victoria Stodden},
  title={The Scientific Method in Practice: Reproducibility in the Computational Sciences},
  year={2010},
  month={February},
  day={9},
  journal={MIT Sloan Research Paper},
  number={4773-10},
  url={https://ssrn.com/abstract=1550193.37},
  doi={10.2139/ssrn.1550193}
}

@article{taufer-sc-reproducibility,
  author={Michela Taufer},
  title={SC16 Explores Reproducibility for Advanced Computing Through Student Cluster Competition},
  url={http://sc16.supercomputing.org/2016/03/16/sc16-explores-reproducibility-advanced-computing-student-competition-michela-taufer/index.html}
}

@inbook {vcs-facilitating-reproducibility,
  title = {Facilitating Reproducibility in Scientific Computing: Principles and Practice},
  author = {Bailey, David H. and Borwein, Jonathan M. and Stodden, Victoria},
  author = {},
  publisher = {John Wiley \& Sons, Inc.},
  isbn = {9781118865064},
  url = {http://dx.doi.org/10.1002/9781118865064.ch9},
  doi = {10.1002/9781118865064.ch9},
  pages = {205--231},
  keywords = {high-performance computing, high-precision arithmetic, mathematical physics, numerical reproducibility, performance reporting, scientific computing, statistical overfitting, symbolic computing},
  booktitle = {Reproducibility},
  year = {2016}
}

@misc{mps-report-2016,
  title = {Workshops to Gauge the Impact of Requirements for Public Access to Data Produced by NSF-funded Research in Mathematics and the Physical Sciences},
  author = {Robert Hanisch and Michael Hildreth and Leah McEwen and Victoria Stodden and Gordon Watts and Daniel S. Katz and Natalie Meyers and Ashley E. Sands},
  url = {https://mpsopendata.crc.nd.edu/images/Reports/MPS_Workshop_Report_FinalVersion.pdf},
  year = {2016}
}

@ARTICLE{ieee-754-2008-redline, 
  journal={IEEE Std 754-2008 (Revision of IEEE Std 754-1985) - Redline}, 
  title={IEEE Standard for Floating-Point Arithmetic - Redline}, 
  year={2008}, 
  pages={1-82}, 
  keywords={Arithmetic;Floating-point arithmetic;IEEE standards;754-2008;NaN;arithmetic;binary;computer;decimal;exponent;floating-point;format;interchange;number;rounding;significand;subnormal}, 
  doi={10.1109/IEEESTD.2008.5976968}, 
  month={Aug}
}

@ARTICLE{ieee-754-2008, 
  journal={IEEE Std 754-2008}, 
  title={IEEE Standard for Floating-Point Arithmetic}, 
  year={2008}, 
  pages={1-70}, 
  keywords={IEEE standards;floating point arithmetic;programming;IEEE standard;arithmetic formats;computer programming;decimal floating-point arithmetic;754-2008;NaN;arithmetic;binary;computer;decimal;exponent;floating-point;format;interchange;number;rounding;significand;subnormal}, 
  doi={10.1109/IEEESTD.2008.4610935}, 
  month={Aug}
}

@misc{top-500-perfdev,
  title={PERFORMANCE DEVELOPMENT},
  url={https://www.top500.org/statistics/perfdevel/}
}

@article{bicep2-no-grav-waves,
  title={No evidence for or against gravitational waves},
  author={Ron Cowen},
  year={2014},
  month={May},
  day={29},
  journal={Nature},
  doi={10.1038/nature.2014.15322}
}

@article{bicep2-grav-wave-scrutiny-1,
  author={Michael J. Mortonson and Uroš Seljak},
  title={A joint analysis of Planck and BICEP2 B modes including dust polarization uncertainty},
  journal={Journal of Cosmology and Astroparticle Physics},
  volume={2014},
  number={10},
  pages={035},
  url={http://stacks.iop.org/1475-7516/2014/i=10/a=035},
  year={2014},
  abstract={We analyze BICEP2 and Planck data using a model that includes CMB lensing, gravity waves, and polarized dust. Recently published Planck dust polarization maps have highlighted the difficulty of estimating the amount of dust polarization in low intensity regions, suggesting that the polarization fractions have considerable uncertainties and may be significantly higher than previous predictions. In this paper, we start by assuming nothing about the dust polarization except for the power spectrum shape, which we take to be C l BB ,dust l -2.42 . The resulting joint BICEP2+Planck analysis favors solutions without gravity waves, and the upper limit on the tensor-to-scalar ratio is r <0.11, a slight improvement relative to the Planck analysis alone which gives r <0.13 (95\% c.l.). The estimated amplitude of the dust polarization power spectrum agrees with expectations for this field based on both HI column density and Planck polarization measurements at 353 GHz in the BICEP2 field. Including the latter constraint on the dust spectrum amplitude in our analysis improves the limit further to r < 0.09, placing strong constraints on theories of inflation (e.g., models with r >0.14 are excluded with 99.5\% confidence). We address the cross-correlation analysis of BICEP2 at 150 GHz with BICEP1 at 100 GHz as a test of foreground contamination. We find that the null hypothesis of dust and lensing with 0 r = gives $\delta$ $\chi$ 2 < 2 relative to the hypothesis of no dust, so the frequency analysis does not strongly favor either model over the other. We also discuss how more accurate dust polarization maps may improve our constraints. If the dust polarization is measured perfectly, the limit can reach r < 0.05 (or the corresponding detection significance if the observed dust signal plus the expected lensing signal is below the BICEP2 observations), but this degrades quickly to almost no improvement if the dust calibration error is 20\% or larger or if the dust maps are not processed through the BICEP2 pipeline, inducing sampling variance noise.}
}

@article{bicep2-grav-wave-scrutiny-2,
  author={Raphael Flauger and J. Colin Hill and David N. Spergel},
  title={Toward an understanding of foreground emission in the BICEP2 region},
  journal={Journal of Cosmology and Astroparticle Physics},
  volume={2014},
  number={08},
  pages={039},
  url={http://stacks.iop.org/1475-7516/2014/i=08/a=039},
  year={2014},
  abstract={BICEP2 has reported the detection of a degree-scale B -mode polarization pattern in the Cosmic Microwave Background (CMB) and has interpreted the measurement as evidence for primordial gravitational waves. Motivated by the profound importance of the discovery of gravitational waves from the early Universe, we examine to what extent a combination of Galactic foregrounds and lensed E -modes could be responsible for the signal. We reanalyze the BICEP2 results and show that the 100 ×150 GHz and 150 ×150 GHz data are consistent with a cosmology with r =0.2 and negligible foregrounds, but also with a cosmology with r =0 and a significant dust polarization signal. We give independent estimates of the dust polarization signal in the BICEP2 region using a number of different approaches: (1) data-driven models based on Planck 353 GHz intensity, polarization fractions inferred from the same Planck data used by the BICEP2 team but corrected for CMB and CIB contributions, and polarization angles from starlight polarization data or the Planck sky model; (2) the same set of pre- Planck models used by the BICEP2 team but taking into account the higher polarization fractions observed in the CMB- and CIB-corrected map; (3) a measurement of neutral hydrogen gas column density N HI in the BICEP2 region combined with an extrapolation of a relation between HI column density and dust polarization derived by Planck ; and (4) a dust polarization map based on digitized Planck data, which we only use as a final cross-check. While these approaches are consistent with each other, the expected amplitude of the dust polarization power spectrum remains uncertain by about a factor of three. The lower end of the prediction leaves room for a primordial contribution, but at the higher end the dust in combination with the standard CMB lensing signal could account for the BICEP2 observations, without requiring the existence of primordial gravitational waves. By measuring the cross-correlations between the pre- Planck templates used in the BICEP2 analysis and between different versions of a data-based template, we emphasize that cross-correlations between models are very sensitive to noise in the polarization angles and that measured cross-correlations are likely underestimates of the contribution of foregrounds to the map. These results suggest that BICEP1 and BICEP2 data alone cannot distinguish between foregrounds and a primordial gravitational wave signal, and that future Keck Array observations at 100 GHz and Planck observations at higher frequencies will be crucial to determine whether the signal is of primordial origin.}
}

@misc{gnu-libc-rounding,
  title={The GNU C Library: Rounding},
  url={https://www.gnu.org/software/libc/manual/html_node/Rounding.html}
}

@book{higham-numerical-accuracy-and-stability,
  author = {Higham, N.},
  title = {Accuracy and Stability of Numerical Algorithms},
  publisher = {Society for Industrial and Applied Mathematics},
  year = {2002},
  doi = {10.1137/1.9780898718027},
  address = {},
  edition   = {Second},
  URL = {http://epubs.siam.org/doi/abs/10.1137/1.9780898718027},
  eprint = {http://epubs.siam.org/doi/pdf/10.1137/1.9780898718027}
}

@misc{dhb-numerical-bugs,
  title={Resolving Numerical Anomalies in Scientific Computation},
  author={David H. Bailey},
  year={2008},
  month={February},
  Day={11},
  url={https://pubarchive.lbl.gov/islandora/object/ir\%3A150532},
  eprint={http://www.davidhbailey.com/dhbpapers/numerical-bugs.pdf}
}

@article{dhb-hp-comp,
  title = "High-precision computation: Mathematical physics and dynamics",
  journal = "Applied Mathematics and Computation",
  volume = "218",
  number = "20",
  pages = "10106 - 10121",
  year = "2012",
  note = "",
  issn = "0096-3003",
  doi = "http://dx.doi.org/10.1016/j.amc.2012.03.087",
  url = "http://www.sciencedirect.com/science/article/pii/S0096300312003505",
  author = "D.H. Bailey and R. Barrio and J.M. Borwein",
  keywords = "High-precision computation",
  keywords = "Mathematical physics",
  keywords = "Dynamical systems",
  keywords = "Experimental mathematics"
}

@Article{dhb-hp-math-physics,
  AUTHOR = {Bailey, David H. and Borwein, Jonathan M.},
  TITLE = {High-Precision Arithmetic in Mathematical Physics},
  JOURNAL = {Mathematics},
  VOLUME = {3},
  YEAR = {2015},
  NUMBER = {2},
  PAGES = {337--367},
  URL = {http://www.mdpi.com/2227-7390/3/2/337},
  ISSN = {2227-7390},
  ABSTRACT = {For many scientific calculations, particularly those involving empirical data, IEEE 32-bit floating-point arithmetic produces results of sufficient accuracy, while for other applications IEEE 64-bit floating-point is more appropriate. But for some very demanding applications, even higher levels of precision are often required. This article discusses the challenge of high-precision computation, in the context of mathematical physics, and highlights what facilities are required to support future computation, in light of emerging developments in computer architecture.},
  DOI = {10.3390/math3020337}
}

@INPROCEEDINGS{precimonious, 
	author={C. Rubio-González and Cuong Nguyen and Hong Diep Nguyen and J. Demmel and W. Kahan and K. Sen and D. H. Bailey and C. Iancu and D. Hough}, 
	booktitle={2013 SC - International Conference for High Performance Computing, Networking, Storage and Analysis (SC)}, 
	title={Precimonious: Tuning assistant for floating-point precision}, 
	year={2013}, 
	pages={1-12}, 
	keywords={floating point arithmetic;mathematics computing;numerical analysis;program debugging;program diagnostics;program testing;GNU Scientific Library;NAS parallel benchmarks;PRECIMONIOUS;dynamic program analysis tool;floating-point program precision tuning;floating-point program variables;numerical analysis;numerical errors;numerical programs;Accuracy;Algorithm design and analysis;Heuristic algorithms;Numerical analysis;Partitioning algorithms;Performance analysis;Tuning;delta-debugging algorithm;dynamic program analysis;floating-point arithmetic;mixed precision;program optimization}, 
	doi={10.1145/2503210.2503296}, 
	ISSN={2167-4329}, 
	month={Nov}
}

@article{default-reproducible,
  author={V. Stodden and D. H. Bailey and J. Borswein and R. J. LeVeque and W. Rider and W. Stein},
  title = {Setting the Default to Reproducible},
  journal= {ICERM Workshop 2013 Report},
  url={https://www.carma.newcastle.edu.au/jon/icerm12.pdf},
  eprint={http://www.davidhbailey.com/dhbpapers/icerm-report.pdf}
}

@misc{ipol-website,
  title={IPOL Journal - Image Processing On Line},
  url={http://www.ipol.im/}
}

@ARTICLE{codeocean-live, 
	author={J. L. Ayala}, 
	journal={IEEE Design Test}, 
	title={Code Ocean Is Live: Upload Your Algorithms}, 
	year={2017}, 
	volume={34}, 
	number={3}, 
	pages={108-109}, 
	doi={10.1109/MDAT.2017.2692207}, 
	ISSN={2168-2356}, 
	month={June}
}
